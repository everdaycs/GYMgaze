#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ring Sonar Simulator - ç¯å½¢è¶…å£°æ³¢é›·è¾¾æ¨¡æ‹Ÿå™¨

ç”¨12ä¸ªå‡åŒ€åˆ†å¸ƒçš„è¶…å£°æ³¢ä¼ æ„Ÿå™¨æ›¿ä»£ä¸»åŠ¨æ‘„åƒå¤´
- ä¼ æ„Ÿå™¨å¸ƒå±€ï¼šåŠå¾„15cmåœ†ç›˜è¾¹ç¼˜ï¼Œå‡åŒ€åˆ†å¸ƒ12ä¸ªä¼ æ„Ÿå™¨
- ä¼ æ„Ÿå™¨å‚æ•°ï¼š65Â° FoVï¼Œæœ€å¤§æ¢æµ‹è·ç¦»12.5m
- 2Dä¿¯è§†å›¾ç¯å¢ƒ
"""

import numpy as np
import os
import sys
import random
import math
import cv2
import time
import argparse
from typing import List, Tuple, Dict, Any, Optional
from dataclasses import dataclass

import torch
import torch.nn as nn
import torch.nn.functional as F

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
_PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

# å¯¼å…¥å·¥å…·å‡½æ•°
from src.utils.geometry import (
    clamp, angnorm_deg, angdiff_deg,
    add_global_feature
)
from src.utils.fisher import SonarFisherCalculator

# å¯¼å…¥é…ç½®
from configs import (
    SimulationConfig, RobotPhysicsConfig, SensorConfig, WorldConfig,
    DEFAULT_CONFIG, DEMO_CONFIG, print_config
)

# å¯¼å…¥ä¼ æ„Ÿå™¨å®šä¹‰
from src.simulator.sensors import SonarSensor

# å¯¼å…¥è®­ç»ƒå¥½çš„å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹
try:
    from src.models.global_map import GlobalMapPredictor, ConvBlock
    MODEL_AVAILABLE = True
except ImportError:
    try:
        # å…¼å®¹æ—§è·¯å¾„
        from train_global_map_model import GlobalMapPredictor, ConvBlock
        MODEL_AVAILABLE = True
    except ImportError:
        MODEL_AVAILABLE = False
        print("Warning: Could not import GlobalMapPredictor model")


# ------------------------------- æ ¸å¿ƒæ¨¡æ‹Ÿå™¨ -------------------------------- #

class RingSonarCore:
    """
    ç¯å½¢è¶…å£°æ³¢é›·è¾¾æ ¸å¿ƒæ¨¡æ‹Ÿå™¨
    - 12ä¸ªè¶…å£°æ³¢ä¼ æ„Ÿå™¨å‡åŒ€åˆ†å¸ƒåœ¨15cmåŠå¾„åœ†ç›˜ä¸Š
    - æ¯ä¸ªä¼ æ„Ÿå™¨ç‹¬ç«‹æ‰«æ65Â° FoV
    - 2Dä¸–ç•Œï¼Œä¿¯è§†å›¾
    """
    
    def __init__(self,
                 world_width: float = None,
                 world_height: float = None,
                 pixel_per_meter: int = 20,
                 robot_size: float = None,
                 sensor_ring_radius: float = None,
                 num_sensors: int = None,
                 sensor_fov: float = None,
                 sensor_max_range: float = None,
                 feature_map_size: int = 100,
                 feature_map_resolution: float = 0.25,
                 control_frequency: float = 5.0,
                 trigger_mode: str = "sequential",  # è§¦å‘æ¨¡å¼
                 dt: float = None,
                 config: SimulationConfig = None):  # æ–°å¢ï¼šä½¿ç”¨é…ç½®å¯¹è±¡
        
        # ä½¿ç”¨é…ç½®å¯¹è±¡ï¼ˆå¦‚æœæä¾›ï¼‰æˆ–ä½¿ç”¨é»˜è®¤é…ç½®
        if config is None:
            config = DEFAULT_CONFIG
        self.config = config
        
        # ä¸–ç•Œå‚æ•°ï¼ˆé…ç½®ä¼˜å…ˆï¼Œç„¶åæ˜¯å‚æ•°ï¼Œæœ€åæ˜¯é»˜è®¤å€¼ï¼‰
        self.world_width = float(world_width if world_width is not None else config.world.world_width)
        self.world_height = float(world_height if world_height is not None else config.world.world_height)
        self.pixel_per_meter = int(pixel_per_meter)
        self.robot_size = float(robot_size if robot_size is not None else config.robot.robot_size)
        
        # ä¼ æ„Ÿå™¨å‚æ•°
        self.sensor_ring_radius = float(sensor_ring_radius if sensor_ring_radius is not None else config.sensor.ring_radius)
        self.num_sensors = int(num_sensors if num_sensors is not None else config.sensor.num_sensors)
        self.sensor_fov = float(sensor_fov if sensor_fov is not None else config.sensor.fov_angle)
        self.sensor_max_range = float(sensor_max_range if sensor_max_range is not None else config.sensor.max_range)
        
        # è§¦å‘æ¨¡å¼é…ç½®
        self.trigger_mode = trigger_mode
        self._init_trigger_config()
        
        # åˆå§‹åŒ–ä¼ æ„Ÿå™¨é˜µåˆ—
        self.sensors: List[SonarSensor] = []
        self._init_sensors()
        
        # Fisheråœ°å›¾ (2Dï¼Œæœºå™¨äººä¸­å¿ƒçš„å±€éƒ¨è§†å›¾)
        self.feature_map_size = int(feature_map_size)
        self.feature_map_resolution = float(feature_map_resolution)
        self.feature_map = np.zeros((self.feature_map_size, self.feature_map_size), dtype=np.float32)
        self.global_feature_map_size = int(max(self.world_width, self.world_height) * 2 / self.feature_map_resolution)
        self.global_feature_map = np.zeros((self.global_feature_map_size, self.global_feature_map_size), dtype=np.float32)
        
        # æ—¶é—´ä¸æ§åˆ¶ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„dtï¼‰
        self.dt = float(dt if dt is not None else config.robot.dt)
        self.sim_time = 0.0
        
        # æœºå™¨äººçŠ¶æ€
        self.robot_pos = np.array([self.world_width / 2, self.world_height / 2], dtype=np.float64)
        self.robot_angle = 0.0           # deg, æœºå™¨äººæœå‘
        self._robot_angle_rad_cache = 0.0  # ç¼“å­˜å¼§åº¦å€¼ï¼Œé¿å…é‡å¤è½¬æ¢
        self.velocity = 0.0              # m/s
        self.angular_velocity = 0.0      # rad/s
        self.max_linear_velocity = config.robot.max_linear_velocity
        self.max_angular_velocity = config.robot.max_angular_velocity
        
        # ä¼ æ„Ÿå™¨è§¦å‘æ§åˆ¶
        self.sensor_trigger_interval = config.robot.sensor_trigger_interval
        self.sensor_trigger_counter = 0
        
        # ä¼ æ„Ÿå™¨è¯»æ•° (æ¯ä¸ªä¼ æ„Ÿå™¨çš„è·ç¦»æµ‹é‡)
        self.sonar_readings = np.full(self.num_sensors, self.sensor_max_range, dtype=np.float32)
        
        # è·Ÿè¸ªæœ¬å¸§å“ªäº›ä¼ æ„Ÿå™¨è¢«æ‰«æè¿‡ï¼ˆç”¨äºoccupancy gridæ›´æ–°ï¼‰
        self.active_sensors_this_frame = set()
        
        # éšœç¢ç‰©
        self.obstacles = []
        self._have_map = False
        
        # è¯Šæ–­ä¿¡æ¯
        self.step_counter = 0
        self._collision_occurred = False
        self._stuck_counter = 0
        
        # ç¼“å­˜çš„è½¬æ¢
        self.width = int(self.world_width * self.pixel_per_meter)
        self.height = int(self.world_height * self.pixel_per_meter)
        
        # Fisherè®¡ç®—å™¨ï¼ˆè¶…å£°æ³¢é›·è¾¾ä¸“ç”¨ï¼‰
        self.fisher_calc = SonarFisherCalculator(
            num_sensors=self.num_sensors,
            sensor_spacing=360.0 / self.num_sensors,
            sensor_fov=self.sensor_fov,
            max_range=self.sensor_max_range
        )
    
    # -------- è§¦å‘æ¨¡å¼é…ç½® -------- #
    
    def _init_trigger_config(self):
        """åˆå§‹åŒ–è§¦å‘é…ç½®"""
        if self.trigger_mode == "sector":
            # æ‰‡åŒºè½®è¯¢æ¨¡å¼ï¼šåˆ†4ä¸ªæ‰‡åŒºï¼Œæ¯ä¸ªæ‰‡åŒº3ä¸ªä¼ æ„Ÿå™¨
            # ä¼ æ„Ÿå™¨ID: 0(0Â°), 1(30Â°), 2(60Â°), 3(90Â°), ..., 11(330Â°)
            self.sectors = {
                "front": [11, 0, 1],      # 330Â°, 0Â°, 30Â° (æœºå™¨äººå‰æ–¹Â±30Â°)
                "right": [2, 3, 4],       # 60Â°, 90Â°, 120Â° (å³ä¾§)
                "back": [5, 6, 7],        # 150Â°, 180Â°, 210Â° (åæ–¹)
                "left": [8, 9, 10]        # 240Â°, 270Â°, 300Â° (å·¦ä¾§)
            }
            self.sector_sequence = ["front", "right", "back", "left"]
            self.current_sector_index = 0
            
            print(f"è§¦å‘æ¨¡å¼: {self.trigger_mode}")
            print(f"æ‰‡åŒºé…ç½®: {self.sectors}")
            print(f"è½®è¯¢é¡ºåº: {self.sector_sequence}")
            
        elif self.trigger_mode == "sequential":
            # é¡ºåºæ‰«ææ¨¡å¼ï¼šæ¯æ¬¡åªè§¦å‘1ä¸ªä¼ æ„Ÿå™¨ï¼Œå®Œå…¨é¿å…å¹²æ‰°
            self.current_sensor_index = 0
            print(f"è§¦å‘æ¨¡å¼: {self.trigger_mode} (é¡ºåºæ‰«æï¼Œå®Œå…¨é¿å…å¹²æ‰°)")
            print(f"æ‰«æé¡ºåº: 0 â†’ 1 â†’ 2 â†’ ... â†’ 11 â†’ 0")
            
        elif self.trigger_mode == "interleaved":
            # äº¤é”™æ‰«ææ¨¡å¼ï¼šä¼ æ„Ÿå™¨é—´éš”è¶³å¤Ÿå¤§ï¼Œé¿å…å¹²æ‰°
            # å¥‡æ•°è½®æ¬¡ï¼š0, 2, 4, 6, 8, 10 (é—´éš”60Â°)
            # å¶æ•°è½®æ¬¡ï¼š1, 3, 5, 7, 9, 11 (é—´éš”60Â°)
            self.interleaved_groups = [
                [0, 2, 4, 6, 8, 10],  # å¶æ•°IDï¼Œé—´éš”60Â°
                [1, 3, 5, 7, 9, 11]   # å¥‡æ•°IDï¼Œé—´éš”60Â°
            ]
            self.current_group_index = 0
            self.current_sensor_in_group = 0
            print(f"è§¦å‘æ¨¡å¼: {self.trigger_mode} (äº¤é”™æ‰«æ)")
            print(f"ç»„1: {self.interleaved_groups[0]} (é—´éš”60Â°)")
            print(f"ç»„2: {self.interleaved_groups[1]} (é—´éš”60Â°)")
        else:
            # all æˆ–å…¶ä»–æ¨¡å¼
            print(f"è§¦å‘æ¨¡å¼: {self.trigger_mode}")
    
    # -------- ä¼ æ„Ÿå™¨åˆå§‹åŒ– -------- #
    
    def _init_sensors(self):
        """åˆå§‹åŒ–12ä¸ªå‡åŒ€åˆ†å¸ƒçš„ä¼ æ„Ÿå™¨"""
        self.sensors.clear()
        angle_step = 360.0 / self.num_sensors
        
        for i in range(self.num_sensors):
            angle = i * angle_step  # ä¼ æ„Ÿå™¨ç›¸å¯¹æœºå™¨äººçš„è§’åº¦
            angle_rad = math.radians(angle)
            
            # è®¡ç®—ä¼ æ„Ÿå™¨åœ¨æœºå™¨äººåæ ‡ç³»ä¸­çš„åç§»
            offset_x = self.sensor_ring_radius * math.cos(angle_rad)
            offset_y = self.sensor_ring_radius * math.sin(angle_rad)
            
            sensor = SonarSensor(
                id=i,
                angle=angle,
                offset_x=offset_x,
                offset_y=offset_y,
                fov_angle=self.sensor_fov,
                max_range=self.sensor_max_range
            )
            self.sensors.append(sensor)
        
        print(f"Initialized {self.num_sensors} sonar sensors in a ring (radius={self.sensor_ring_radius}m)")
    
    # -------- å…¬å…±API -------- #
    
    def reset(self, regenerate_map: bool = True, seed: Optional[int] = None) -> None:
        """é‡ç½®ç¯å¢ƒ"""
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)
        
        if regenerate_map or not self._have_map:
            self._gen_obstacles(num_obstacles=20)
            self._have_map = True
        
        self.robot_pos = self._find_safe_start()
        self.robot_angle = float(random.randint(0, 360))
        self._robot_angle_rad_cache = math.radians(self.robot_angle)
        
        self.velocity = 0.0
        self.angular_velocity = 0.0
        
        self.sim_time = 0.0
        
        self.feature_map.fill(0.0)
        self.global_feature_map.fill(0.0)
        self.sonar_readings.fill(self.sensor_max_range)
        
        self._collision_occurred = False
        self._stuck_counter = 0
        self.step_counter = 0
    
    def set_velocity(self, linear_vel: float, angular_vel: float) -> None:
        """è®¾ç½®æœºå™¨äººé€Ÿåº¦"""
        self.velocity = clamp(float(linear_vel), -5.0, 5.0)
        self.angular_velocity = clamp(float(angular_vel), -1.5, 1.5)
    
    def step(self) -> None:
        """æ‰§è¡Œä¸€æ­¥ä»¿çœŸ"""
        prev_pos = self.robot_pos.copy()
        self._collision_occurred = False
        
        # æ›´æ–°æ—¶é—´
        self.sim_time += self.dt
        
        # æ›´æ–°ä½å§¿
        self._update_robot()
        
        # æ£€æµ‹ç¢°æ’ï¼ˆé€šè¿‡ä½ç§»åˆ¤æ–­ï¼‰
        moved = np.linalg.norm(self.robot_pos - prev_pos)
        if moved < 0.01:
            self._collision_occurred = True
            self._stuck_counter += 1
        else:
            self._stuck_counter = 0
        
        # æ‰«ææ‰€æœ‰ä¼ æ„Ÿå™¨
        self._scan_all_sensors()
        
        self.step_counter += 1
    
    def update_maps(self) -> None:
        """æ›´æ–°Fisherä¿¡æ¯åœ°å›¾"""
        self._apply_feature_decay()
        self._detect_and_add_features_to_global_map()
        self._extract_local_feature_map()
    
    def state(self) -> Dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€"""
        return {
            'position': self.robot_pos.copy(),
            'angle': float(self.robot_angle),
            'linear_velocity': float(self.velocity),
            'angular_velocity': float(self.angular_velocity),
            'sonar_readings': self.sonar_readings.copy(),
            'step_counter': int(self.step_counter),
            'collision_occurred': bool(self._collision_occurred),
            'stuck_counter': int(self._stuck_counter),
            'sim_time': float(self.sim_time)
        }
    
    def fisher_map_stats(self) -> Dict[str, float]:
        """Fisheråœ°å›¾ç»Ÿè®¡ä¿¡æ¯"""
        flat = self.feature_map.ravel()
        nz = flat[flat > 0]
        if nz.size == 0:
            return {'mean_fisher': 0.0, 'total_features': 0.0, 'density': 0.0}
        return {
            'mean_fisher': float(nz.mean()),
            'total_features': float(nz.size),
            'density': float(nz.size) / float(flat.size)
        }
    
    # -------- å†…éƒ¨å®ç° -------- #
    
    def _inside_world(self, x: float, y: float) -> bool:
        """æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨ä¸–ç•ŒèŒƒå›´å†…"""
        return 0.0 <= x < self.world_width and 0.0 <= y < self.world_height
    
    def _gen_obstacles(self, num_obstacles: int = 20):
        """ç”Ÿæˆéšœç¢ç‰©"""
        self.obstacles.clear()
        wall = 0.5
        
        # è¾¹ç•Œå¢™
        self.obstacles += [
            ('rect', (0.0, 0.0, self.world_width, wall)),
            ('rect', (0.0, self.world_height - wall, self.world_width, wall)),
            ('rect', (0.0, 0.0, wall, self.world_height)),
            ('rect', (self.world_width - wall, 0.0, wall, self.world_height))
        ]
        
        # éšæœºéšœç¢ç‰©
        for _ in range(num_obstacles):
            x = random.uniform(2.5, self.world_width - 2.5)
            y = random.uniform(2.5, self.world_height - 2.5)
            w = random.uniform(2.0, 5.0)
            h = random.uniform(2.0, 5.0)
            self.obstacles.append(('rect', (x, y, w, h)))
    
    def _find_safe_start(self) -> np.ndarray:
        """å¯»æ‰¾å®‰å…¨çš„èµ·å§‹ä½ç½®"""
        margin = self.robot_size + 0.5
        for _ in range(100):
            p = np.array([
                random.uniform(margin, self.world_width - margin),
                random.uniform(margin, self.world_height - margin)
            ], dtype=np.float64)
            if self._position_safe(p):
                return p
        
        # å¤‡ç”¨ï¼šä¸­å¿ƒä½ç½®
        c = np.array([self.world_width / 2, self.world_height / 2], dtype=np.float64)
        return c
    
    def _position_safe(self, pos: np.ndarray) -> bool:
        """æ£€æŸ¥ä½ç½®æ˜¯å¦å®‰å…¨"""
        if (pos[0] < self.robot_size or pos[0] > self.world_width - self.robot_size or
            pos[1] < self.robot_size or pos[1] > self.world_height - self.robot_size):
            return False
        return not self._collide_at(pos)
    
    def _point_in_obstacle(self, x: float, y: float) -> bool:
        """æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨éšœç¢ç‰©å†…"""
        for kind, data in self.obstacles:
            if kind == 'rect':
                ox, oy, w, h = data
                if ox <= x <= ox + w and oy <= y <= oy + h:
                    return True
        return False
    
    def _collide_at(self, target_pos: np.ndarray) -> bool:
        """æ£€æŸ¥ä½ç½®æ˜¯å¦ç¢°æ’"""
        rx, ry = target_pos[0], target_pos[1]
        rs = self.robot_size
        for kind, data in self.obstacles:
            if kind == 'rect':
                x, y, w, h = data
                cx = clamp(rx, x, x + w)
                cy = clamp(ry, y, y + h)
                if math.hypot(rx - cx, ry - cy) < rs:
                    return True
        return False
    
    def _update_robot(self):
        """æ›´æ–°æœºå™¨äººä½å§¿"""
        # ä½¿ç”¨ç¼“å­˜çš„å¼§åº¦å€¼è®¡ç®—ä½ç½®å¢é‡
        delta_x = math.cos(self._robot_angle_rad_cache) * self.velocity * self.dt
        delta_y = math.sin(self._robot_angle_rad_cache) * self.velocity * self.dt
        
        # æ›´æ–°ä½ç½®
        new_pos = self.robot_pos.copy()
        new_pos[0] = clamp(new_pos[0] + delta_x, self.robot_size, self.world_width - self.robot_size)
        new_pos[1] = clamp(new_pos[1] + delta_y, self.robot_size, self.world_height - self.robot_size)
        
        if self._collide_at(new_pos):
            self._handle_collision()
        else:
            self.robot_pos = new_pos
            # æ›´æ–°è§’åº¦å’Œç¼“å­˜
            self.robot_angle = (self.robot_angle + math.degrees(self.angular_velocity * self.dt)) % 360.0
            self._robot_angle_rad_cache = math.radians(self.robot_angle)
    
    def _handle_collision(self):
        """å¤„ç†ç¢°æ’"""
        self.velocity = clamp(-self.velocity * random.uniform(0.5, 1.0) + random.uniform(-0.5, 0.5),
                              -self.max_linear_velocity, self.max_linear_velocity)
        if abs(self.angular_velocity) < 0.1:
            self.angular_velocity = random.choice([-1, 1]) * random.uniform(0.3, 0.8)
        else:
            self.angular_velocity = clamp(-self.angular_velocity + random.uniform(-0.2, 0.2),
                                          -self.max_angular_velocity, self.max_angular_velocity)
    
    # -------- ä¼ æ„Ÿå™¨æ‰«æ -------- #
    
    def _get_active_sensor_ids(self) -> List[int]:
        """è·å–å½“å‰å¸§åº”æ¿€æ´»çš„ä¼ æ„Ÿå™¨IDåˆ—è¡¨"""
        if self.trigger_mode == "sector":
            current_sector_name = self.sector_sequence[self.current_sector_index]
            return self.sectors[current_sector_name]
        elif self.trigger_mode == "sequential":
            return [self.current_sensor_index]
        elif self.trigger_mode == "interleaved":
            current_group = self.interleaved_groups[self.current_group_index]
            return [current_group[self.current_sensor_in_group]]
        else:  # "all"
            return list(range(self.num_sensors))
    
    def _scan_all_sensors(self):
        """æ‰«æä¼ æ„Ÿå™¨ï¼ˆæ ¹æ®è§¦å‘æ¨¡å¼ï¼‰"""
        # æ¸…ç©ºæœ¬å¸§æ´»è·ƒä¼ æ„Ÿå™¨è®°å½•
        self.active_sensors_this_frame.clear()
        
        # è·å–éœ€è¦æ¿€æ´»çš„ä¼ æ„Ÿå™¨ID
        active_ids = self._get_active_sensor_ids()
        
        # æ‰«ææ¿€æ´»çš„ä¼ æ„Ÿå™¨
        for sensor_id in active_ids:
            sensor = self.sensors[sensor_id]
            distance = self._scan_single_sensor(sensor)
            self.sonar_readings[sensor_id] = distance
            self.active_sensors_this_frame.add(sensor_id)
        
        # æ›´æ–°è§¦å‘æ¨¡å¼çš„ç´¢å¼•
        if self.trigger_mode == "sector":
            self.current_sector_index = (self.current_sector_index + 1) % len(self.sector_sequence)
        elif self.trigger_mode == "sequential":
            self.current_sensor_index = (self.current_sensor_index + 1) % self.num_sensors
        elif self.trigger_mode == "interleaved":
            self.current_sensor_in_group += 1
            if self.current_sensor_in_group >= len(self.interleaved_groups[self.current_group_index]):
                self.current_sensor_in_group = 0
                self.current_group_index = (self.current_group_index + 1) % len(self.interleaved_groups)
    
    def _scan_single_sensor(self, sensor: SonarSensor) -> float:
        """æ‰«æå•ä¸ªä¼ æ„Ÿå™¨ï¼Œè¿”å›æœ€è¿‘éšœç¢ç‰©è·ç¦»"""
        # è·å–ä¼ æ„Ÿå™¨ä¸–ç•Œä½ç½®å’Œæœå‘
        sensor_pos = sensor.get_world_position(self.robot_pos, self.robot_angle)
        sensor_angle = sensor.get_world_angle(self.robot_angle)
        
        # æ‰«æFoVèŒƒå›´å†…çš„å°„çº¿
        min_distance = sensor.max_range
        half_fov = sensor.fov_angle / 2.0
        
        # ä½¿ç”¨å¤šæ¡å°„çº¿æ‰«æFoV
        num_rays = 9  # æ¯ä¸ªä¼ æ„Ÿå™¨9æ¡å°„çº¿
        for i in range(num_rays):
            # è®¡ç®—å°„çº¿è§’åº¦
            if num_rays == 1:
                ray_angle = sensor_angle
            else:
                offset = -half_fov + (i / (num_rays - 1)) * sensor.fov_angle
                ray_angle = (sensor_angle + offset) % 360.0
            
            # æ²¿å°„çº¿å‰è¿›ï¼Œæ£€æµ‹éšœç¢ç‰©
            ray_angle_rad = math.radians(ray_angle)
            step = 0.1  # æ­¥è¿›è·ç¦»
            distance = 0.0
            
            while distance < sensor.max_range:
                distance += step
                wx = sensor_pos[0] + math.cos(ray_angle_rad) * distance
                wy = sensor_pos[1] + math.sin(ray_angle_rad) * distance
                
                # æ£€æŸ¥æ˜¯å¦å‡ºç•Œæˆ–ç¢°åˆ°éšœç¢ç‰©
                if not self._inside_world(wx, wy) or self._point_in_obstacle(wx, wy):
                    min_distance = min(min_distance, distance)
                    break
        
        return min_distance
    
    # -------- Fisheråœ°å›¾æ›´æ–° -------- #
    
    def _apply_feature_decay(self):
        """åº”ç”¨ç‰¹å¾è¡°å‡"""
        self.global_feature_map *= (1.0 - 5e-6)
        self.global_feature_map[self.global_feature_map < 0.1] = 0.0
    
    def _detect_and_add_features_to_global_map(self):
        """ä»ä¼ æ„Ÿå™¨è¯»æ•°ä¸­æ£€æµ‹å¹¶æ·»åŠ ç‰¹å¾åˆ°å…¨å±€åœ°å›¾"""
        for sensor in self.sensors:
            distance = self.sonar_readings[sensor.id]
            
            # å¦‚æœæ£€æµ‹åˆ°éšœç¢ç‰©ï¼ˆè·ç¦»å°äºæœ€å¤§èŒƒå›´ï¼‰
            if distance < sensor.max_range:
                # è·å–ä¼ æ„Ÿå™¨ä¸–ç•Œä½ç½®å’Œæœå‘
                sensor_pos = sensor.get_world_position(self.robot_pos, self.robot_angle)
                sensor_angle = sensor.get_world_angle(self.robot_angle)
                
                # è®¡ç®—éšœç¢ç‰©ä½ç½®
                angle_rad = math.radians(sensor_angle)
                wx = sensor_pos[0] + math.cos(angle_rad) * distance
                wy = sensor_pos[1] + math.sin(angle_rad) * distance
                
                # è®¡ç®—Fisherä¿¡æ¯
                fisher = self._fisher_at(wx, wy, distance, sensor_angle)
                
                # æ·»åŠ åˆ°å…¨å±€åœ°å›¾
                self._add_global_feature(wx, wy, fisher)
    
    def _fisher_at(self, wx: float, wy: float, distance: float, angle_deg: float) -> float:
        """
        è®¡ç®—ç‰¹å®šä½ç½®çš„Fisherä¿¡æ¯å€¼
        
        è¶…å£°æ³¢é›·è¾¾ç‰ˆæœ¬ï¼š
        - è€ƒè™‘è·ç¦»å› å­ï¼ˆè¿‘è·ç¦»æ›´å¯é ï¼‰
        - è€ƒè™‘ä¼ æ„Ÿå™¨è¦†ç›–åº¦ï¼ˆé‡å åŒºåŸŸæ›´å¯ä¿¡ï¼‰
        - ä¸è€ƒè™‘FOVè´¨é‡ï¼ˆè¶…å£°æ³¢åªæœ‰è·ç¦»ä¿¡æ¯ï¼‰
        """
        # è®¡ç®—ç›¸å¯¹æœºå™¨äººçš„è§’åº¦ï¼ˆå½’ä¸€åŒ–åˆ°0-360ï¼‰
        relative_angle = (angle_deg - self.robot_angle) % 360.0
        
        # ä½¿ç”¨è¶…å£°æ³¢ä¸“ç”¨Fisherè®¡ç®—å™¨
        return self.fisher_calc.compute(
            distance=distance,
            angle_deg=relative_angle
        )
    
    def _add_global_feature(self, wx: float, wy: float, val: float):
        """å°†ç‰¹å¾æ·»åŠ åˆ°å…¨å±€åœ°å›¾"""
        add_global_feature(
            global_map=self.global_feature_map,
            wx=wx, wy=wy,
            fisher_value=val,
            map_size=self.global_feature_map_size,
            resolution=self.feature_map_resolution,
            world_width=self.world_width,
            world_height=self.world_height,
            spread_neighbors=True
        )
    
    def _extract_local_feature_map(self):
        """æå–ä»¥æœºå™¨äººä¸ºä¸­å¿ƒçš„å±€éƒ¨ç‰¹å¾åœ°å›¾"""
        m = self.global_feature_map
        size = self.global_feature_map_size
        res = self.feature_map_resolution
        half = self.feature_map_size // 2
        
        rx = int(self.robot_pos[0] / res + size // 2 - self.world_width // (2 * res))
        ry = int(self.robot_pos[1] / res + size // 2 - self.world_height // (2 * res))
        
        gx0, gy0 = rx - half, ry - half
        gx1, gy1 = gx0 + self.feature_map_size, gy0 + self.feature_map_size
        
        sx0 = max(0, -gx0)
        sy0 = max(0, -gy0)
        sx1 = self.feature_map_size - max(0, gx1 - size)
        sy1 = self.feature_map_size - max(0, gy1 - size)
        
        Gx0 = max(0, gx0)
        Gy0 = max(0, gy0)
        Gx1 = min(size, gx1)
        Gy1 = min(size, gy1)
        
        self.feature_map.fill(0.0)
        if sx0 < sx1 and sy0 < sy1:
            self.feature_map[sy0:sy1, sx0:sx1] = m[Gy0:Gy1, Gx0:Gx1]
        
        # è½»å¾®æ¨¡ç³Š
        self.feature_map = cv2.GaussianBlur(self.feature_map, (3, 3), 0.5)


# ------------------------------- æ¸²æŸ“å™¨ -------------------------------- #

class RingSonarRenderer:
    """
    ç¯å½¢è¶…å£°æ³¢é›·è¾¾æ¸²æŸ“å™¨ - 2Dä¿¯è§†å›¾
    æ˜¾ç¤ºï¼šæœºå™¨äººã€ä¼ æ„Ÿå™¨å¸ƒå±€ã€FoVæ‰‡åŒºã€éšœç¢ç‰©ã€Fisheråœ°å›¾ã€æ …æ ¼å ç”¨å›¾
    """
    
    def __init__(self, core: RingSonarCore, render_mode: Optional[str] = "human", enable_prediction: bool = True):
        self.core = core
        self.render_mode = render_mode
        self.enable_prediction = enable_prediction  # æ˜¯å¦å¯ç”¨éšœç¢ç‰©é¢„æµ‹
        self.world_img = np.ones((core.height, core.width, 3), dtype=np.uint8) * 255
        
        # å…¨å±€æ …æ ¼å ç”¨å›¾ (Global Occupancy Grid Map)
        # åˆ†è¾¨ç‡ï¼šæ¯ä¸ªæ …æ ¼ä»£è¡¨0.1ç±³
        self.grid_resolution = 0.1  # ç±³/æ …æ ¼
        self.grid_width = int(core.world_width / self.grid_resolution)
        self.grid_height = int(core.world_height / self.grid_resolution)
        
        # å ç”¨æ …æ ¼åœ°å›¾ (0=éšœç¢ç‰©, 127=æœªçŸ¥, 255=æ— éšœç¢)
        self.occupancy_grid = np.ones((self.grid_height, self.grid_width), dtype=np.uint8) * 127
        # è®¿é—®è®¡æ•°ï¼šè®°å½•æ¯ä¸ªæ …æ ¼è¢«æ‰«æçš„æ¬¡æ•°
        self.visit_count = np.zeros((self.grid_height, self.grid_width), dtype=np.uint16)
        
        # éšœç¢ç‰©é¢„æµ‹åœ°å›¾ (0-255: 0=ç¡®å®šæ— éšœç¢, 255=ç¡®å®šæœ‰éšœç¢)
        self.obstacle_prediction = np.ones((self.grid_height, self.grid_width), dtype=np.uint8) * 127
        # é¢„æµ‹ç½®ä¿¡åº¦ (0-100: ç½®ä¿¡åº¦ç™¾åˆ†æ¯”)
        self.prediction_confidence = np.zeros((self.grid_height, self.grid_width), dtype=np.uint8)
        
        # å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹ç›¸å…³
        self.sequence_length = 5  # ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
        self.model = None
        self.frame_buffer = []  # å­˜å‚¨å†å²å¸§ç”¨äºæ—¶é—´åºåˆ—
        self.device = torch.device('cpu')  # é»˜è®¤è®¾å¤‡
        
        # åªæœ‰åœ¨å¯ç”¨é¢„æµ‹æ—¶æ‰åŠ è½½æ¨¡å‹
        if self.enable_prediction:
            # å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹é…ç½®
            self.in_channels = 8  # 5å¸§å±€éƒ¨è§‚æµ‹ + å…¨å±€ç´¯ç§¯ + è®¿é—®è®¡æ•° + å·²çŸ¥æ©ç 
            
            # æ™ºèƒ½è®¾å¤‡é€‰æ‹©ï¼šä¼˜å…ˆGPUï¼Œå¦‚æœGPUå†…å­˜ä¸è¶³åˆ™å›é€€åˆ°CPU
            if torch.cuda.is_available():
                try:
                    print("æµ‹è¯•GPUå†…å­˜æ˜¯å¦è¶³å¤Ÿè¿›è¡Œå…¨å±€åœ°å›¾é¢„æµ‹æ¨ç†...")
                    torch.cuda.empty_cache()
                    
                    # åˆ›å»ºæ¨¡å‹å¹¶å°è¯•åŠ è½½åˆ°GPU
                    test_model = GlobalMapPredictor(
                        in_channels=self.in_channels, 
                        base_channels=32
                    ).cuda()
                    
                    # åŠ è½½æƒé‡
                    checkpoint = torch.load('./checkpoints/global_map_model.pth', map_location='cuda')
                    if 'model_state_dict' in checkpoint:
                        test_model.load_state_dict(checkpoint['model_state_dict'])
                    else:
                        test_model.load_state_dict(checkpoint)
                    
                    # å°è¯•ä¸€æ¬¡å®Œæ•´çš„æ¨ç†
                    test_input = torch.randn(1, self.in_channels, 400, 400).cuda()
                    test_model.eval()
                    with torch.no_grad():
                        test_output = test_model(test_input)
                    
                    # æ¸…ç†æµ‹è¯•èµ„æº
                    del test_model, test_input, test_output, checkpoint
                    torch.cuda.empty_cache()
                    
                    self.device = torch.device('cuda')
                    print("âœ… GPUå†…å­˜å……è¶³ï¼Œä½¿ç”¨GPUè¿›è¡Œå…¨å±€åœ°å›¾é¢„æµ‹æ¨ç†")
                except RuntimeError as e:
                    print(f"âŒ GPUå†…å­˜ä¸è¶³: {e}ï¼Œå›é€€åˆ°CPUæ¨ç†")
                    torch.cuda.empty_cache()
                    self.device = torch.device('cpu')
                except FileNotFoundError as e:
                    print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
                    self.device = torch.device('cpu')
            else:
                self.device = torch.device('cpu')
                print("æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUæ¨ç†")
            
            # å°è¯•åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
            self._load_model()
        else:
            print("ğŸ“Š æ•°æ®æ”¶é›†æ¨¡å¼ï¼šå·²ç¦ç”¨éšœç¢ç‰©é¢„æµ‹ä»¥åŠ é€Ÿæ•°æ®æ”¶é›†")
    
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹"""
        if not MODEL_AVAILABLE:
            print("å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿæ‰©æ•£é¢„æµ‹")
            return
        
        model_path = './checkpoints/global_map_model.pth'
        if not os.path.exists(model_path):
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            print("è¯·å…ˆè¿è¡Œ train_global_map_model.py è®­ç»ƒæ¨¡å‹")
            print("å°†ä½¿ç”¨ä¼ ç»Ÿæ‰©æ•£é¢„æµ‹æ–¹æ³•")
            self.model = None
            return
            
        try:
            # åˆ›å»ºæ¨¡å‹å®ä¾‹ - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å‚æ•°
            self.model = GlobalMapPredictor(
                in_channels=self.in_channels, 
                base_channels=32  # åŒ¹é…è®­ç»ƒæ—¶çš„é»˜è®¤å‚æ•°
            ).to(self.device)
            
            # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
            checkpoint = torch.load(model_path, map_location=self.device)
            if 'model_state_dict' in checkpoint:
                self.model.load_state_dict(checkpoint['model_state_dict'])
            else:
                self.model.load_state_dict(checkpoint)
            
            # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            self.model = self.model.to(self.device)
            
            self.model.eval()
            print(f"âœ… æˆåŠŸåŠ è½½å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹: {model_path}")
            print(f"   æ¨ç†è®¾å¤‡: {self.device}")
            print(f"   æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("å°†ä½¿ç”¨ä¼ ç»Ÿæ‰©æ•£é¢„æµ‹æ–¹æ³•")
            self.model = None
    
    def render(self):
        if self.render_mode is None:
            return None
        
        self.world_img.fill(255)
        self._draw_obstacles()
        self._draw_sensor_fov()
        self._draw_robot()
        self._draw_sensor_readings()
        self._draw_trigger_info()  # æ˜¾ç¤ºè§¦å‘æ¨¡å¼ä¿¡æ¯
        self._update_occupancy_grid()
        
        if self.render_mode == "human":
            self._show_windows()
        elif self.render_mode == "rgb_array":
            return self.world_img.copy()
    
    def _w2p(self, wx: float, wy: float) -> Tuple[int, int]:
        """ä¸–ç•Œåæ ‡è½¬åƒç´ åæ ‡"""
        return int(wx * self.core.pixel_per_meter), int(wy * self.core.pixel_per_meter)
    
    def _draw_direction_arrow(self, img: np.ndarray, cx: int, cy: int, 
                             angle_rad: float, velocity: float, scale: float = 1.0):
        """ç»˜åˆ¶ç§»åŠ¨æ–¹å‘ç®­å¤´ï¼ˆç»Ÿä¸€æ–¹æ³•ï¼‰"""
        if abs(velocity) > 0.01:  # ç§»åŠ¨ä¸­
            speed_factor = min(abs(velocity) / 2.0, 1.0)
            arrow_len = int(18 * scale * (0.5 + 0.5 * speed_factor))
            
            if velocity > 0:  # å‰è¿›
                color = (0, 0, 255)  # çº¢è‰²
                thickness = 3
            else:  # åé€€
                color = (0, 165, 255)  # æ©™è‰²
                thickness = 3
                angle_rad += math.pi
                
            ex = int(cx + math.cos(angle_rad) * arrow_len)
            ey = int(cy + math.sin(angle_rad) * arrow_len)
            cv2.arrowedLine(img, (cx, cy), (ex, ey), color, thickness)
        else:  # é™æ­¢
            arrow_len = int(18 * scale * 0.6)
            ex = int(cx + math.cos(angle_rad) * arrow_len)
            ey = int(cy + math.sin(angle_rad) * arrow_len)
            cv2.arrowedLine(img, (cx, cy), (ex, ey), (255, 200, 100), 2)
    
    def _draw_obstacles(self):
        """ç»˜åˆ¶éšœç¢ç‰©"""
        ppm = self.core.pixel_per_meter
        for kind, data in self.core.obstacles:
            if kind == 'rect':
                x, y, w, h = data
                px, py = int(x * ppm), int(y * ppm)
                pw, ph = int(w * ppm), int(h * ppm)
                cv2.rectangle(self.world_img, (px, py), (px + pw, py + ph), (0, 0, 0), -1)
    
    def _draw_robot(self):
        """ç»˜åˆ¶æœºå™¨äººå’Œä¼ æ„Ÿå™¨å¸ƒå±€"""
        ppm = self.core.pixel_per_meter
        cx, cy = self._w2p(self.core.robot_pos[0], self.core.robot_pos[1])
        
        # ç»˜åˆ¶æœºå™¨äººä¸»ä½“
        r = int(self.core.robot_size * ppm)
        cv2.circle(self.world_img, (cx, cy), r, (0, 255, 0), -1)
        
        # ç»˜åˆ¶ç§»åŠ¨æ–¹å‘ç®­å¤´
        angle_rad = math.radians(self.core.robot_angle)
        self._draw_direction_arrow(self.world_img, cx, cy, angle_rad, 
                                   self.core.velocity, ppm / 20)
        
        # ç»˜åˆ¶ä¼ æ„Ÿå™¨ç¯
        ring_r = int(self.core.sensor_ring_radius * ppm)
        cv2.circle(self.world_img, (cx, cy), ring_r, (150, 150, 150), 1)
        
        # ç»˜åˆ¶æ¯ä¸ªä¼ æ„Ÿå™¨
        for sensor in self.core.sensors:
            sx, sy = sensor.get_world_position(self.core.robot_pos, self.core.robot_angle)
            sx_pix, sy_pix = self._w2p(sx, sy)
            cv2.circle(self.world_img, (sx_pix, sy_pix), 3, (255, 0, 255), -1)
    
    def _draw_sensor_fov(self):
        """ç»˜åˆ¶ä¼ æ„Ÿå™¨çš„FoVæ‰‡åŒºï¼ˆæ ¹æ®è§¦å‘æ¨¡å¼ï¼‰"""
        ppm = self.core.pixel_per_meter
        overlay = np.zeros_like(self.world_img)
        
        # ä½¿ç”¨ä¸Šä¸€å¸§æ¿€æ´»çš„ä¼ æ„Ÿå™¨ï¼ˆä»coreçš„è®°å½•ä¸­è·å–ï¼‰
        active_sensor_ids = list(self.core.active_sensors_this_frame)
        
        for sensor in self.core.sensors:
            # åªç»˜åˆ¶æ¿€æ´»çš„ä¼ æ„Ÿå™¨
            if sensor.id not in active_sensor_ids:
                continue
            # è·å–ä¼ æ„Ÿå™¨ä¸–ç•Œä½ç½®å’Œæœå‘
            sx, sy = sensor.get_world_position(self.core.robot_pos, self.core.robot_angle)
            sensor_angle = sensor.get_world_angle(self.core.robot_angle)
            
            sx_pix, sy_pix = self._w2p(sx, sy)
            
            # åˆ›å»ºæ‰‡å½¢çš„ç‚¹åˆ—è¡¨
            fov_pts = [(sx_pix, sy_pix)]
            half_fov = sensor.fov_angle / 2.0
            
            # ä½¿ç”¨å½“å‰ä¼ æ„Ÿå™¨è¯»æ•°ä½œä¸ºç»˜åˆ¶èŒƒå›´
            display_range = min(self.core.sonar_readings[sensor.id], sensor.max_range)
            range_pix = int(display_range * ppm)
            
            # ç»˜åˆ¶æ‰‡å½¢è¾¹ç¼˜
            for angle_offset in np.linspace(-half_fov, half_fov, 20):
                angle = math.radians(sensor_angle + angle_offset)
                ex = int(sx_pix + math.cos(angle) * range_pix)
                ey = int(sy_pix + math.sin(angle) * range_pix)
                ex = clamp(ex, 0, self.core.width - 1)
                ey = clamp(ey, 0, self.core.height - 1)
                fov_pts.append((ex, ey))
            
            # å¡«å……æ‰‡å½¢
            if len(fov_pts) > 2:
                pts = np.array(fov_pts, dtype=np.int32)
                # æ ¹æ®è·ç¦»é€‰æ‹©é¢œè‰²ï¼ˆè¿‘è·ç¦»çº¢è‰²ï¼Œè¿œè·ç¦»è“è‰²ï¼‰
                if display_range < sensor.max_range * 0.5:
                    color = (100, 100, 255)  # çº¢è‰²åå‘
                else:
                    color = (255, 150, 100)  # è“è‰²åå‘
                cv2.fillPoly(overlay, [pts], color)
        
        # æ··åˆoverlay
        cv2.addWeighted(self.world_img, 0.7, overlay, 0.3, 0, self.world_img)
    
    def _draw_sensor_readings(self):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¼ æ„Ÿå™¨è¯»æ•°æ–‡æœ¬"""
        ppm = self.core.pixel_per_meter
        
        for i, sensor in enumerate(self.core.sensors):
            sx, sy = sensor.get_world_position(self.core.robot_pos, self.core.robot_angle)
            sx_pix, sy_pix = self._w2p(sx, sy)
            
            # æ˜¾ç¤ºè·ç¦»è¯»æ•°
            distance = self.core.sonar_readings[sensor.id]
            text = f"{distance:.1f}"
            
            # æ–‡æœ¬ä½ç½®ç¨å¾®åç§»
            text_x = sx_pix + 5
            text_y = sy_pix - 5
            
            cv2.putText(self.world_img, text, (text_x, text_y),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1)
    
    def _draw_trigger_info(self):
        """æ˜¾ç¤ºè§¦å‘æ¨¡å¼ä¿¡æ¯"""
        active_ids = list(self.core.active_sensors_this_frame)
        
        # æ ¹æ®è§¦å‘æ¨¡å¼æ˜¾ç¤ºä¸åŒä¿¡æ¯
        mode_info = {
            "sector": ("Sector Polling (3 sensors)", "Warning: May have interference", (380, 85)),
            "sequential": ("Sequential (1 sensor)", "Status: No interference!", (350, 85)),
            "interleaved": ("Interleaved (1 sensor)", "Status: 60deg spacing, minimal interference", (420, 85)),
            "all": ("All Sensors (12 sensors)", "Warning: High interference in real world", (420, 60))
        }
        
        mode, status, box_size = mode_info.get(self.core.trigger_mode, 
                                               ("Unknown Mode", "Unknown status", (420, 85)))
        
        # ç»˜åˆ¶ä¿¡æ¯æ¡†
        cv2.rectangle(self.world_img, (5, 5), box_size, (255, 255, 255), -1)
        cv2.rectangle(self.world_img, (5, 5), box_size, (0, 0, 0), 2)
        
        # æ˜¾ç¤ºè§¦å‘æ¨¡å¼
        cv2.putText(self.world_img, f"Trigger: {mode}", (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 0, 255), 2)
        
        # æ˜¾ç¤ºæ´»è·ƒä¼ æ„Ÿå™¨ï¼ˆå¦‚æœæ•°é‡å°‘äº4ä¸ªï¼‰
        if len(active_ids) <= 4:
            angles = [f"{sid * 30}deg" for sid in active_ids]
            sensor_text = f"Active: {active_ids} ({', '.join(angles)})"
            cv2.putText(self.world_img, sensor_text, (10, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 128, 0), 1)
        
        # æ˜¾ç¤ºçŠ¶æ€
        color = (0, 200, 0) if "No interference" in status else (0, 100, 200)
        y_pos = 75 if len(active_ids) <= 4 else 50
        cv2.putText(self.world_img, status, (10, y_pos),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
    
    def _update_occupancy_grid(self):
        """æ›´æ–°å…¨å±€æ …æ ¼å ç”¨å›¾ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨NumPyæ•°ç»„æ“ä½œ"""
        # åˆ›å»ºä¸´æ—¶æ ‡è®°æ•°ç»„ï¼ˆ0=æœªå¤„ç†, 1=æ— éšœç¢, 2=éšœç¢ç‰©ï¼‰
        temp_grid = np.zeros((self.grid_height, self.grid_width), dtype=np.uint8)
        
        # åªä½¿ç”¨æœ¬å¸§å®é™…æ‰«æè¿‡çš„ä¼ æ„Ÿå™¨
        for sensor in self.core.sensors:
            if sensor.id not in self.core.active_sensors_this_frame:
                continue
                
            # è·å–ä¼ æ„Ÿå™¨ä¸–ç•Œä½ç½®å’Œæœå‘
            sx, sy = sensor.get_world_position(self.core.robot_pos, self.core.robot_angle)
            sensor_angle = sensor.get_world_angle(self.core.robot_angle)
            detected_distance = self.core.sonar_readings[sensor.id]
            
            # åœ†é”¥å½¢FoVæ‰«æ
            half_fov = sensor.fov_angle / 2.0
            num_angle_steps = max(3, int(sensor.fov_angle / 2))
            
            for angle_offset in np.linspace(-half_fov, half_fov, num_angle_steps):
                ray_angle = math.radians(sensor_angle + angle_offset)
                cos_ray = math.cos(ray_angle)
                sin_ray = math.sin(ray_angle)
                
                # æ²¿å°„çº¿æ ‡è®°æ— éšœç¢åŒºåŸŸ
                num_steps = max(2, int(detected_distance / (self.grid_resolution * 0.5)))
                distances = np.linspace(0, detected_distance, num_steps)
                
                wx = sx + cos_ray * distances
                wy = sy + sin_ray * distances
                
                gx = (wx / self.grid_resolution).astype(int)
                gy = (wy / self.grid_resolution).astype(int)
                
                # è¿‡æ»¤è¾¹ç•Œå†…çš„ç‚¹
                valid = (gx >= 0) & (gx < self.grid_width) & (gy >= 0) & (gy < self.grid_height)
                temp_grid[gy[valid], gx[valid]] = 1  # æ ‡è®°ä¸ºæ— éšœç¢
                
                # æ ‡è®°éšœç¢ç‰©ï¼ˆå¦‚æœæœªè¾¾åˆ°æœ€å¤§è·ç¦»ï¼‰
                if detected_distance < sensor.max_range * 0.95:
                    wx_obs = sx + cos_ray * detected_distance
                    wy_obs = sy + sin_ray * detected_distance
                    gx_obs = int(wx_obs / self.grid_resolution)
                    gy_obs = int(wy_obs / self.grid_resolution)
                    
                    if 0 <= gx_obs < self.grid_width and 0 <= gy_obs < self.grid_height:
                        if temp_grid[gy_obs, gx_obs] == 0:  # åªåœ¨æœªæ ‡è®°ä¸ºæ— éšœç¢æ—¶è®¾ç½®
                            temp_grid[gy_obs, gx_obs] = 2  # æ ‡è®°ä¸ºéšœç¢ç‰©
        
        # æ‰¹é‡æ›´æ–°å ç”¨æ …æ ¼
        free_mask = (temp_grid == 1)
        obstacle_mask = (temp_grid == 2)
        
        self.occupancy_grid[free_mask] = 255
        self.occupancy_grid[obstacle_mask] = 50
        
        # æ›´æ–°è®¿é—®è®¡æ•°ï¼ˆé˜²æ­¢æº¢å‡ºï¼‰
        visited_mask = (temp_grid > 0)
        self.visit_count[visited_mask] = np.minimum(65535, self.visit_count[visited_mask] + 1)
        
        # ç®¡ç†å¸§ç¼“å†²åŒºï¼ˆç”¨äºæ—¶ç©ºæ¨ç†ï¼‰
        self._update_frame_buffer()
        
        # æ›´æ–°éšœç¢ç‰©é¢„æµ‹
        self._predict_obstacles()
    
    def _update_frame_buffer(self):
        """æ›´æ–°å¸§ç¼“å†²åŒºï¼Œç”¨äºæ—¶ç©ºæ¨ç†"""
        # åˆ›å»ºå½“å‰å¸§çš„æ•°æ®
        current_frame = {
            'occupancy': self.occupancy_grid.copy(),
            'visit_count': self.visit_count.copy(),
            'robot_pos': self.core.robot_pos.copy(),
            'step': self.core.step_counter
        }
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.frame_buffer.append(current_frame)
        
        # ä¿æŒç¼“å†²åŒºå¤§å°ä¸ºsequence_length
        if len(self.frame_buffer) > self.sequence_length:
            self.frame_buffer.pop(0)
    
    def _predict_obstacles(self):
        """
        åŸºäºå…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹é¢„æµ‹éšœç¢ç‰©ä½ç½®
        
        å¦‚æœæ¨¡å‹å¯ç”¨ï¼Œä½¿ç”¨æ·±åº¦å­¦ä¹ é¢„æµ‹ï¼›å¦åˆ™ä½¿ç”¨ä¼ ç»Ÿæ‰©æ•£æ–¹æ³•
        """
        # å¦‚æœç¦ç”¨äº†é¢„æµ‹ï¼Œç›´æ¥è¿”å›
        if not self.enable_prediction:
            return
            
        if self.model is not None and len(self.frame_buffer) >= self.sequence_length:
            # ä½¿ç”¨è®­ç»ƒå¥½çš„å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹
            self._predict_with_model()
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ‰©æ•£é¢„æµ‹æ–¹æ³•
            self._predict_with_diffusion()
    
    def _predict_with_model(self):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        try:
            with torch.no_grad():
                # å‡†å¤‡è¾“å…¥åºåˆ—
                sequence_frames = self.frame_buffer[-self.sequence_length:]
                
                # è·å–æœ€åä¸€å¸§çš„å…¨å±€ç´¯ç§¯ä¿¡æ¯
                last_frame = sequence_frames[-1]
                
                # æ„å»ºæ—¶é—´åºåˆ—è¾“å…¥ (T, H, W) - å±€éƒ¨è§‚æµ‹åºåˆ—
                local_seq = np.stack([
                    f['occupancy'].astype(np.float32) / 255.0 
                    for f in sequence_frames
                ], axis=0)  # (T, H, W)
                
                # å…¨å±€ç´¯ç§¯åœ°å›¾ï¼ˆä½¿ç”¨å½“å‰çš„å ç”¨æ …æ ¼ä½œä¸ºå…¨å±€ç´¯ç§¯ï¼‰
                global_acc = self.occupancy_grid.astype(np.float32) / 255.0  # (H, W)
                
                # è®¿é—®è®¡æ•°å½’ä¸€åŒ–
                global_visit = np.clip(self.visit_count.astype(np.float32) / 100.0, 0, 1)  # (H, W)
                
                # åˆ›å»ºå·²çŸ¥åŒºåŸŸæ©ç  (H, W) - é127çš„åŒºåŸŸä¸ºå·²çŸ¥
                known_mask = (self.occupancy_grid != 127).astype(np.float32)
                
                # ç»„åˆè¾“å…¥ (T+3, H, W)
                # - Tå¸§å±€éƒ¨è§‚æµ‹
                # - 1å¸§å…¨å±€ç´¯ç§¯
                # - 1å¸§è®¿é—®è®¡æ•°
                # - 1å¸§å·²çŸ¥æ©ç 
                input_tensor = np.concatenate([
                    local_seq,                          # (T, H, W)
                    global_acc[np.newaxis, :, :],       # (1, H, W)
                    global_visit[np.newaxis, :, :],     # (1, H, W)
                    known_mask[np.newaxis, :, :]        # (1, H, W)
                ], axis=0)  # (T+3, H, W)
                
                # è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶æ·»åŠ æ‰¹æ¬¡ç»´åº¦ (1, C, H, W)
                input_tensor = torch.FloatTensor(input_tensor).unsqueeze(0).to(self.device)
                
                # æ¨¡å‹æ¨ç†
                output = self.model(input_tensor)
                
                # å¤„ç†è¾“å‡º (B, H, W) -> (H, W)
                prediction = output.squeeze(0).cpu().numpy()
                
                # è½¬æ¢ä¸º0-255èŒƒå›´ï¼ˆæ¨¡å‹è¾“å‡º0=ç©ºé—²ï¼Œ1=éšœç¢ç‰©ï¼‰
                # è½¬æ¢ä¸ºå ç”¨æ …æ ¼æ ¼å¼ï¼š0=éšœç¢ç‰©ï¼Œ255=ç©ºé—²ï¼Œ127=æœªçŸ¥
                prediction_occupancy = np.zeros_like(prediction, dtype=np.uint8)
                prediction_occupancy[prediction < 0.3] = 255  # é«˜å¯ä¿¡åº¦ç©ºé—²
                prediction_occupancy[prediction > 0.7] = 0    # é«˜å¯ä¿¡åº¦éšœç¢ç‰©
                prediction_occupancy[(prediction >= 0.3) & (prediction <= 0.7)] = 127  # ä¸ç¡®å®šåŒºåŸŸ
                
                # æ›´æ–°é¢„æµ‹åœ°å›¾
                self.obstacle_prediction = prediction_occupancy
                
                # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆç¦»0.5è¶Šè¿œç½®ä¿¡åº¦è¶Šé«˜ï¼‰
                confidence = np.abs(prediction - 0.5) * 200  # 0-100
                self.prediction_confidence = confidence.astype(np.uint8)
                
        except Exception as e:
            print(f"æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}ï¼Œåˆ‡æ¢åˆ°ä¼ ç»Ÿæ–¹æ³•")
            import traceback
            traceback.print_exc()
            self._predict_with_diffusion()
    
    def _predict_with_diffusion(self):
        """
        åŸºäºæ‰©æ•£æ¨¡å‹é¢„æµ‹éšœç¢ç‰©ä½ç½®
        
        æ ¸å¿ƒæ€æƒ³ï¼š
        1. ç©ºé—²ç©ºé—´çš„è¾¹ç•Œå¾ˆå¯èƒ½æ˜¯éšœç¢ç‰©
        2. ä½¿ç”¨å½¢æ€å­¦æ“ä½œæ£€æµ‹è¾¹ç•Œ
        3. åŸºäºå‘¨å›´ç©ºé—²ç©ºé—´å¯†åº¦è®¡ç®—ç½®ä¿¡åº¦
        """
        # åˆ›å»ºäºŒå€¼åŒ–åœ°å›¾ï¼šå·²çŸ¥ç©ºé—²åŒºåŸŸ
        free_space = (self.occupancy_grid > 200).astype(np.uint8)
        known_obstacles = (self.occupancy_grid < 80).astype(np.uint8)
        
        # æ–¹æ³•1: è¾¹ç•Œæ£€æµ‹ - ç©ºé—²ç©ºé—´è¾¹ç¼˜æ‰©æ•£
        # è†¨èƒ€ç©ºé—²åŒºåŸŸï¼Œæ‰¾åˆ°è¾¹ç•Œ
        kernel_size = 3
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        
        # è†¨èƒ€ç©ºé—²åŒºåŸŸï¼ˆæ‰©æ•£1-2ä¸ªæ …æ ¼ï¼‰
        dilated_free = cv2.dilate(free_space, kernel, iterations=2)
        
        # è¾¹ç•Œ = è†¨èƒ€åŒºåŸŸ - åŸå§‹ç©ºé—²åŒºåŸŸ
        boundary = cv2.subtract(dilated_free, free_space)
        
        # æ’é™¤å·²çŸ¥çš„ç©ºé—²åŒºåŸŸå’Œå·²çŸ¥çš„éšœç¢ç‰©
        unknown_mask = (self.occupancy_grid > 100) & (self.occupancy_grid < 200)
        potential_obstacles = boundary & unknown_mask.astype(np.uint8)
        
        # æ–¹æ³•2: åŸºäºé‚»åŸŸå¯†åº¦çš„æ¦‚ç‡æ‰©æ•£
        # è®¡ç®—æ¯ä¸ªæ …æ ¼å‘¨å›´çš„ç©ºé—²ç©ºé—´å¯†åº¦
        kernel_large = np.ones((5, 5), dtype=np.float32) / 25.0
        free_density = cv2.filter2D(free_space.astype(np.float32), -1, kernel_large)
        
        # é«˜å¯†åº¦ç©ºé—²ç©ºé—´è¾¹ç¼˜ -> é«˜æ¦‚ç‡éšœç¢ç‰©
        # ä½¿ç”¨æ¢¯åº¦æ£€æµ‹å¯†åº¦å˜åŒ–
        gradient_x = cv2.Sobel(free_density, cv2.CV_32F, 1, 0, ksize=3)
        gradient_y = cv2.Sobel(free_density, cv2.CV_32F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)
        
        # å½’ä¸€åŒ–æ¢¯åº¦åˆ° 0-255
        if gradient_magnitude.max() > 0:
            gradient_norm = (gradient_magnitude / gradient_magnitude.max() * 255).astype(np.uint8)
        else:
            gradient_norm = np.zeros_like(gradient_magnitude, dtype=np.uint8)
        
        # æ–¹æ³•3: æ–¹å‘æ€§æ‰©æ•£ - è€ƒè™‘ä¼ æ„Ÿå™¨è§†çº¿æ–¹å‘
        # ä»æœºå™¨äººä½ç½®å‘å¤–æ‰©æ•£ï¼Œæœªè®¿é—®åŒºåŸŸåœ¨å·²çŸ¥ç©ºé—²åŒºåŸŸåæ–¹å¯èƒ½æ˜¯éšœç¢ç‰©
        robot_gx = int(self.core.robot_pos[0] / self.grid_resolution)
        robot_gy = int(self.core.robot_pos[1] / self.grid_resolution)
        
        # åˆ›å»ºè·ç¦»åœ°å›¾
        y_coords, x_coords = np.ogrid[:self.grid_height, :self.grid_width]
        distance_from_robot = np.sqrt((x_coords - robot_gx)**2 + (y_coords - robot_gy)**2)
        
        # ç»¼åˆé¢„æµ‹ï¼šç»„åˆå¤šç§æ–¹æ³•
        # æƒé‡ï¼šè¾¹ç•Œæ£€æµ‹(40%) + æ¢¯åº¦æ£€æµ‹(40%) + è·ç¦»è¡°å‡(20%)
        prediction = np.zeros_like(self.obstacle_prediction, dtype=np.float32)
        
        # è¾¹ç•Œè´¡çŒ®ï¼šè¾¹ç•ŒåŒºåŸŸæ ‡è®°ä¸ºå¯èƒ½çš„éšœç¢ç‰©
        prediction += potential_obstacles.astype(np.float32) * 200.0 * 0.4
        
        # æ¢¯åº¦è´¡çŒ®ï¼šæ¢¯åº¦å¤§çš„åŒºåŸŸå¯èƒ½æ˜¯éšœç¢ç‰©
        prediction += gradient_norm.astype(np.float32) * 0.4
        
        # è·ç¦»è¡°å‡ï¼šç¦»æœºå™¨äººè¿œä¸”æœªè®¿é—®çš„åŒºåŸŸï¼Œé™ä½é¢„æµ‹ç½®ä¿¡åº¦
        distance_factor = np.clip(1.0 - distance_from_robot / (self.grid_width * 0.3), 0, 1)
        unvisited_mask = (self.visit_count == 0).astype(np.float32)
        prediction += gradient_norm.astype(np.float32) * distance_factor * unvisited_mask * 0.2
        
        # è£å‰ªåˆ° 0-255
        prediction = np.clip(prediction, 0, 255).astype(np.uint8)
        
        # å·²çŸ¥åŒºåŸŸä¿æŒä¸å˜
        prediction[free_space > 0] = 0  # å·²çŸ¥ç©ºé—² -> é¢„æµ‹ä¸ºæ— éšœç¢
        prediction[known_obstacles > 0] = 255  # å·²çŸ¥éšœç¢ -> é¢„æµ‹ä¸ºéšœç¢
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼šåŸºäºå‘¨å›´å·²çŸ¥ä¿¡æ¯çš„æ•°é‡
        kernel_conf = np.ones((5, 5), dtype=np.float32)
        known_mask = ((self.occupancy_grid < 80) | (self.occupancy_grid > 200)).astype(np.float32)
        confidence = cv2.filter2D(known_mask, -1, kernel_conf) / 25.0 * 100
        confidence = np.clip(confidence, 0, 100).astype(np.uint8)
        
        # æ›´æ–°é¢„æµ‹åœ°å›¾
        self.obstacle_prediction = prediction
        self.prediction_confidence = confidence
    
    def reset_grid(self):
        """é‡ç½®æ …æ ¼åœ°å›¾"""
        self.visit_count.fill(0)
        self.occupancy_grid.fill(127)
        self.obstacle_prediction.fill(127)
        self.prediction_confidence.fill(0)
    
    def _show_windows(self):
        """æ˜¾ç¤ºçª—å£"""
        # ä¸–ç•Œè§†å›¾
        cv2.imshow("Ring Sonar Simulation", self.world_img)
        
        # Fisheråœ°å›¾è§†å›¾
        fmap = self.core.feature_map
        vmax = float(np.max(fmap))
        if vmax > 0:
            norm = (fmap / vmax * 255).astype(np.uint8)
        else:
            norm = np.zeros_like(fmap, dtype=np.uint8)
        heat = cv2.applyColorMap(norm, cv2.COLORMAP_JET)
        
        # æ ‡è®°æœºå™¨äººä¸­å¿ƒ
        c = self.core.feature_map_size // 2
        cv2.circle(heat, (c, c), 3, (255, 255, 255), -1)
        
        # ç»˜åˆ¶æœºå™¨äººæœå‘
        L = 10
        ex = int(c + math.cos(math.radians(self.core.robot_angle)) * L)
        ey = int(c + math.sin(math.radians(self.core.robot_angle)) * L)
        cv2.arrowedLine(heat, (c, c), (ex, ey), (255, 255, 255), 2)
        
        view = cv2.resize(heat, (600, 600), interpolation=cv2.INTER_NEAREST)
        stats = self.core.fisher_map_stats()
        cv2.putText(view, "Fisher Information Map", (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(view, f"Features: {int(stats['total_features'])}", (10, 560),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        cv2.putText(view, f"Avg Fisher: {stats['mean_fisher']:.2f}", (150, 560),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        cv2.imshow("Feature Map", view)
        
        # æ …æ ¼å ç”¨å›¾è§†å›¾ (SLAM-like)
        # 0=æœªçŸ¥(ç°), 127=å¯èƒ½æ— éšœç¢(æµ…ç°), 255=ç¡®è®¤æ— éšœç¢(ç™½)
        # è½¬æ¢ä¸ºå¯è§†åŒ–ï¼šåè½¬é¢œè‰²ä½¿éšœç¢ç‰©ä¸ºé»‘è‰²
        grid_vis = self.occupancy_grid.copy()
        
        # åœ¨æ …æ ¼å›¾ä¸Šæ ‡è®°æœºå™¨äººä½ç½®
        robot_gx = int(self.core.robot_pos[0] / self.grid_resolution)
        robot_gy = int(self.core.robot_pos[1] / self.grid_resolution)
        
        # è½¬æ¢ä¸ºå½©è‰²å›¾ä»¥ç»˜åˆ¶æœºå™¨äºº
        grid_color = cv2.cvtColor(grid_vis, cv2.COLOR_GRAY2BGR)
        
        # ç»˜åˆ¶æœºå™¨äººå’Œæ–¹å‘ç®­å¤´
        if 0 <= robot_gx < self.grid_width and 0 <= robot_gy < self.grid_height:
            robot_r = max(2, int(self.core.robot_size / self.grid_resolution))
            cv2.circle(grid_color, (robot_gx, robot_gy), robot_r, (0, 0, 255), -1)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„ç®­å¤´ç»˜åˆ¶æ–¹æ³•
            angle_rad = math.radians(self.core.robot_angle)
            self._draw_direction_arrow(grid_color, robot_gx, robot_gy, angle_rad, 
                                      self.core.velocity, 1.0)
        
        # ç¼©æ”¾æ˜¾ç¤º
        scale_factor = max(1, 600 // max(self.grid_width, self.grid_height))
        grid_display = cv2.resize(grid_color, 
                                  (self.grid_width * scale_factor, self.grid_height * scale_factor),
                                  interpolation=cv2.INTER_NEAREST)
        
        # è®¡ç®—åœ°å›¾ç»Ÿè®¡ä¿¡æ¯
        explored_cells = np.sum(self.visit_count > 0)
        total_cells = self.grid_width * self.grid_height
        coverage = explored_cells / total_cells * 100
        
        obstacle_cells = np.sum(self.occupancy_grid < 50)
        free_cells = np.sum(self.occupancy_grid > 200)
        
        # æ·»åŠ æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
        cv2.putText(grid_display, "Global Occupancy Grid Map", (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(grid_display, f"Resolution: {self.grid_resolution}m/cell", (10, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        cv2.putText(grid_display, f"Explored: {coverage:.1f}%", (10, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        cv2.putText(grid_display, f"Free: {free_cells} | Obstacle: {obstacle_cells}", (10, 90),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 0), 1)
        
        cv2.imshow("Occupancy Grid", grid_display)
        
        # éšœç¢ç‰©é¢„æµ‹åœ°å›¾å¯è§†åŒ–
        self._show_obstacle_prediction()
    
    def _show_obstacle_prediction(self):
        """æ˜¾ç¤ºéšœç¢ç‰©é¢„æµ‹åœ°å›¾"""
        # åˆ›å»ºçƒ­åŠ›å›¾ï¼š0=æ— éšœç¢(è“), 127=æœªçŸ¥(ç»¿), 255=éšœç¢(çº¢)
        prediction_colored = cv2.applyColorMap(self.obstacle_prediction, cv2.COLORMAP_JET)
        
        # å åŠ ç½®ä¿¡åº¦ï¼ˆé€æ˜åº¦ï¼‰
        # é«˜ç½®ä¿¡åº¦åŒºåŸŸæ›´ä¸é€æ˜
        confidence_alpha = (self.prediction_confidence / 100.0 * 0.8 + 0.2)  # 0.2-1.0
        
        # åœ¨é¢„æµ‹å›¾ä¸Šæ ‡è®°å·²çŸ¥ä¿¡æ¯
        # å·²çŸ¥ç©ºé—²ï¼šç»¿è‰²è¾¹æ¡†
        free_mask = (self.occupancy_grid > 200)
        prediction_colored[free_mask] = [0, 255, 0]  # ç»¿è‰²
        
        # å·²çŸ¥éšœç¢ï¼šçº¢è‰²è¾¹æ¡†
        obstacle_mask = (self.occupancy_grid < 80)
        prediction_colored[obstacle_mask] = [0, 0, 255]  # çº¢è‰²
        
        # æ ‡è®°æœºå™¨äººä½ç½®
        robot_gx = int(self.core.robot_pos[0] / self.grid_resolution)
        robot_gy = int(self.core.robot_pos[1] / self.grid_resolution)
        
        if 0 <= robot_gx < self.grid_width and 0 <= robot_gy < self.grid_height:
            robot_r = max(2, int(self.core.robot_size / self.grid_resolution))
            cv2.circle(prediction_colored, (robot_gx, robot_gy), robot_r, (255, 255, 255), -1)
            
            # ç»˜åˆ¶æ–¹å‘ç®­å¤´
            angle_rad = math.radians(self.core.robot_angle)
            self._draw_direction_arrow(prediction_colored, robot_gx, robot_gy, angle_rad, 
                                      self.core.velocity, 1.0)
        
        # ç¼©æ”¾æ˜¾ç¤º
        scale_factor = max(1, 600 // max(self.grid_width, self.grid_height))
        pred_display = cv2.resize(prediction_colored, 
                                  (self.grid_width * scale_factor, self.grid_height * scale_factor),
                                  interpolation=cv2.INTER_NEAREST)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        predicted_obstacles = np.sum((self.obstacle_prediction > 180) & 
                                     (self.occupancy_grid > 100) & 
                                     (self.occupancy_grid < 200))
        avg_confidence = np.mean(self.prediction_confidence[self.prediction_confidence > 0])
        high_conf_predictions = np.sum(self.prediction_confidence > 70)
        
        # æ·»åŠ æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
        model_type = "Global Map Predictor" if self.model is not None and len(self.frame_buffer) >= self.sequence_length else "Diffusion Model"
        cv2.putText(pred_display, f"Obstacle Prediction ({model_type})", (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # æ˜¾ç¤ºå¸§ç¼“å†²çŠ¶æ€
        if self.model is not None:
            buffer_status = f"Buffer: {len(self.frame_buffer)}/{self.sequence_length}"
            cv2.putText(pred_display, buffer_status, (10, 50),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        cv2.putText(pred_display, f"Predicted Obstacles: {predicted_obstacles}", (10, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        cv2.putText(pred_display, f"Avg Confidence: {avg_confidence:.1f}%", (10, 70),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        cv2.putText(pred_display, f"High Conf Cells: {high_conf_predictions}", (10, 90),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        
        # å›¾ä¾‹
        legend_y = pred_display.shape[0] - 60
        cv2.putText(pred_display, "Legend:", (10, legend_y),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)
        cv2.rectangle(pred_display, (10, legend_y + 5), (30, legend_y + 15), (0, 255, 0), -1)
        cv2.putText(pred_display, "= Known Free", (35, legend_y + 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)
        cv2.rectangle(pred_display, (10, legend_y + 20), (30, legend_y + 30), (0, 0, 255), -1)
        cv2.putText(pred_display, "= Known Obstacle", (35, legend_y + 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)
        cv2.putText(pred_display, "Blue->Red = Predicted Probability", (10, legend_y + 45),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)
        
        cv2.imshow("Obstacle Prediction", pred_display)


# ------------------------------- ä¸»ç¨‹åº -------------------------------- #

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Ring Sonar Simulator')
    parser.add_argument('--headless', action='store_true', help='æ— å¯è§†åŒ–æ¨¡å¼')
    parser.add_argument('--realtime', action='store_true', help='å®æ—¶é€Ÿåº¦è¿è¡Œ')
    parser.add_argument('--steps', type=int, default=10000000, help='ä»¿çœŸæ­¥æ•°')
    parser.add_argument('--world-size', type=float, default=40.0, help='ä¸–ç•Œå¤§å°(ç±³)')
    parser.add_argument('--speed', type=float, default=1.0, help='é€Ÿåº¦å€ç‡ (0.5=æ…¢ä¸€å€, 2.0=å¿«ä¸€å€)')
    parser.add_argument('--trigger-mode', type=str, default='sequential', 
                       choices=['sequential', 'interleaved', 'sector', 'all'], 
                       help='ä¼ æ„Ÿå™¨è§¦å‘æ¨¡å¼:\n'
                            '  sequential=é¡ºåºæ‰«æ(æ¨è,æ— å¹²æ‰°)\n'
                            '  interleaved=äº¤é”™æ‰«æ(60Â°é—´éš”,ä½å¹²æ‰°)\n'
                            '  sector=æ‰‡åŒºè½®è¯¢(å¯èƒ½æœ‰å¹²æ‰°)\n'
                            '  all=å…¨éƒ¨è§¦å‘(é«˜å¹²æ‰°)')
    parser.add_argument('--demo-mode', action='store_true', 
                       help='æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨è¾ƒæ…¢çš„é€Ÿåº¦ä¾¿äºè§‚å¯Ÿ')
    parser.add_argument('--use-default-config', action='store_true',
                       help='ä½¿ç”¨ä¸è®­ç»ƒæ•°æ®ç›¸åŒçš„é»˜è®¤é…ç½®ï¼ˆæ¨èç”¨äºæ¨ç†ï¼‰')
    args = parser.parse_args()
    
    # é€‰æ‹©é…ç½®
    if args.demo_mode:
        config = DEMO_CONFIG
        config_name = "æ¼”ç¤ºé…ç½® (DEMO_CONFIG)"
    elif args.use_default_config:
        config = DEFAULT_CONFIG
        config_name = "é»˜è®¤é…ç½® (DEFAULT_CONFIG)"
    else:
        # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
        config = SimulationConfig(
            robot=RobotPhysicsConfig(
                dt=0.05 / args.speed,  # åŸºäºé€Ÿåº¦å€ç‡è°ƒæ•´
                sensor_trigger_interval=1  # äº¤äº’æ¨¡å¼ä¸‹æ¯æ­¥è§¦å‘
            ),
            world=WorldConfig(
                world_width=args.world_size,
                world_height=args.world_size
            )
        )
        config_name = "è‡ªå®šä¹‰é…ç½®"
    
    print("å¯åŠ¨ç¯å½¢è¶…å£°æ³¢é›·è¾¾æ¨¡æ‹Ÿå™¨...")
    print_config(config, config_name)
    print(f"  - æ— ç•Œé¢æ¨¡å¼: {args.headless}")
    print(f"  - å®æ—¶æ¨¡å¼: {args.realtime}")
    print(f"  - é€Ÿåº¦å€ç‡: {args.speed}x")
    print(f"  - è§¦å‘æ¨¡å¼: {args.trigger_mode}")
    print(f"  - ä»¿çœŸæ­¥æ•°: {args.steps}")
    
    if args.demo_mode:
        print("\n" + "="*60)
        print("ğŸš€ å…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹æ¼”ç¤º")
        print("="*60)
        print("è¯¥æ¼”ç¤ºå°†å±•ç¤ºå…¨å±€åœ°å›¾é¢„æµ‹æ¨¡å‹å¦‚ä½•åˆ©ç”¨æ—¶é—´åºåˆ—")
        print("ä¿¡æ¯è¿›è¡ŒSLAMé£æ ¼çš„å…¨å±€åœ°å›¾é‡å»ºå’Œéšœç¢ç‰©é¢„æµ‹")
        print("æŒ‰ 'q' æˆ– ESC é€€å‡ºæ¼”ç¤º")
        print("="*60)
    
    # åˆ›å»ºæ ¸å¿ƒæ¨¡æ‹Ÿå™¨ï¼ˆä½¿ç”¨é…ç½®ï¼‰
    core = RingSonarCore(
        world_width=args.world_size, 
        world_height=args.world_size, 
        trigger_mode=args.trigger_mode,
        config=config
    )
    core.reset(regenerate_map=True)
    
    if not args.headless:
        renderer = RingSonarRenderer(core, render_mode="human")
    else:
        renderer = None
    
    init = core.state()
    print(f"æœºå™¨äººåˆå§‹ä½ç½®: [{init['position'][0]:.2f}, {init['position'][1]:.2f}] m")
    print(f"ä¼ æ„Ÿå™¨æ•°é‡: {core.num_sensors}, ç¯åŠå¾„: {core.sensor_ring_radius}m")
    print(f"æ—¶é—´æ­¥é•¿: {core.dt}s, ä¼ æ„Ÿå™¨è§¦å‘é—´éš”: {core.sensor_trigger_interval}æ­¥")
    
    start_real = time.time()
    expected_sim_t = 0.0
    
    # é€Ÿåº¦å˜åŒ–è®¡æ•°å™¨
    velocity_change_counter = 0
    
    try:
        for step in range(args.steps):
            # ä½¿ç”¨é…ç½®ä¸­çš„é€Ÿåº¦å˜åŒ–é—´éš”å’Œéšæœºé€Ÿåº¦
            velocity_change_counter += 1
            if velocity_change_counter >= config.robot.velocity_change_interval:
                velocity_change_counter = 0
                linear_vel, angular_vel = config.robot.get_random_velocity()
                core.set_velocity(linear_vel, angular_vel)
            
            core.step()
            core.update_maps()
            
            if step % 50 == 0:
                st = core.state()
                f_stats = core.fisher_map_stats()
                print(f"Step {step:4d} (t={st['sim_time']:6.1f}s): "
                      f"Pos=[{st['position'][0]:6.2f},{st['position'][1]:6.2f}]m, "
                      f"Vel={st['linear_velocity']:5.2f}m/s, "
                      f"Fisher={f_stats['total_features']:4.0f}, "
                      f"Sonar={st['sonar_readings'][:4]}")  # æ˜¾ç¤ºå‰4ä¸ªä¼ æ„Ÿå™¨
            
            if renderer:
                renderer.render()
                cv2.waitKey(1)
            
            if args.realtime:
                expected_sim_t += core.dt
                now = time.time() - start_real
                sleep_t = expected_sim_t - now
                if sleep_t > 0:
                    time.sleep(sleep_t)
            else:
                if renderer:
                    time.sleep(0.01)
            
            if renderer:
                k = cv2.waitKey(1) & 0xFF
                if k == ord('q') or k == 27:
                    print("ç”¨æˆ·é€€å‡º")
                    break
    
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­")
    finally:
        st = core.state()
        f_stats = core.fisher_map_stats()
        print("\næœ€ç»ˆç»“æœ:")
        print(f"  ä»¿çœŸæ—¶é—´: {st['sim_time']:.1f} ç§’")
        print(f"  å®é™…è¿è¡Œæ—¶é—´: {time.time() - start_real:.1f} ç§’")
        print(f"  æœ€ç»ˆä½ç½®: [{st['position'][0]:.2f}, {st['position'][1]:.2f}] m")
        print(f"  æ€»æ­¥æ•°: {st['step_counter']}")
        print(f"  å‘ç°ç‰¹å¾: {f_stats['total_features']:.0f}")
        print(f"  å¹³å‡Fisherå€¼: {f_stats['mean_fisher']:.3f}")
        print(f"  ä¼ æ„Ÿå™¨è¯»æ•°:", st['sonar_readings'])
        if not args.headless:
            cv2.destroyAllWindows()
        print("ä»¿çœŸå®Œæˆï¼")
